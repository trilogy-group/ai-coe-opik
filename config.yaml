models:
#  - name: gpt-4o
#    description: "GPT-4o"
  - name: openrouter/qwen/qwen3-14b
    description: "Qwen 3 14B"
    provider: openrouter
#  - name: openrouter/google/gemini-2.5-pro-preview
#    description: "Gemini Pro 2.5 Preview"
#    provider: openrouter
#  - name: openrouter/deepseek/deepseek-r1:free
#    description: "DeepSeek R1"
#    provider: openrouter
#  - name: openrouter/deepseek/deepseek-r1-distill-llama-70b:free
#    description: "DeepSeek R1 Distill Llama 70B"
#    provider: openrouter
#  - name: openrouter/meta-llama/llama-3.3-70b-instruct:free
#    description: "Llama 3.3 70B Instruct"
#    provider: openrouter
#  - name: openrouter/google/gemma-3-27b-it:free
#    description: "Gemma 3 27B"
#    provider: openrouter
#  - name: openrouter/mistralai/mistral-7b-instruct-v0.1
#    description: "Mistral 7B Instruct"
#    provider: openrouter
#  - name: ollama/mixtral:8x7b
#    description: "Mixtral 8x7B"
#    provider: ollama
#  - name: ollama/llama3.2:1b
#    description: "Llama 3.2 1B"
#    provider: ollama
#  - name: ollama/llama3.2:latest
#    description: "Llama 3.2 3B"
#    provider: ollama
#  - name: ollama/qwen2.5:7b
#    description: "Qwen2.5 7B"
#    provider: ollama
#  - name: ollama/deepseek-r1:1.5b
#    description: "DeepSeek-R1-Distill-Qwen-1.5B"
#    provider: ollama
#  - name: ollama/deepseek-r1:7b
#    description: "DeepSeek-R1-Distill-Qwen-7B"
#    provider: ollama
#  - name: ollama/deepseek-r1:8b
#    description: "DeepSeek-R1-Distill-Llama-8B"
#    provider: ollama

# Metrics configuration
metrics:
  # Core Metrics (built-in)
  - name: hallucination
    enabled: true
    description: "Checks if output contains information not supported by context"
  - name: answer_relevance
    enabled: true
    description: "Evaluates if the answer is relevant to the question"
  - name: factual_accuracy
    enabled: true
    description: "Evaluates factual accuracy using G-Eval"

  # Heuristic Metrics (rule-based, no LLM required)
  - name: conciseness
    enabled: true
    description: "Measures output conciseness based on token length"
  - name: response_time
    enabled: false
    description: "Measures model response time"
  - name: format_compliance
    enabled: true
    description: "Checks if output follows requested format (JSON, code block, etc.)"

  # LLM-as-Judge Metrics
  - name: fluency
    enabled: true
    description: "Evaluates grammar, style, and fluency of the output"
  - name: toxicity
    enabled: true
    description: "Checks for harmful, biased, or inappropriate content"
  - name: reasoning_quality
    enabled: true
    description: "Evaluates logical reasoning and critical thinking quality"
  - name: factual_accuracy
    enabled: true
    description: "Evaluates accuracy of factual claims compared to context"
  - name: technical_nuance
    enabled: true
    description: "Evaluates understanding of technical concepts and domain-specific knowledge"
  - name: empathy
    enabled: true
    description: "Evaluates emotional awareness and appropriate tone in responses"
  - name: multistep_reasoning
    enabled: true
    description: "Evaluates ability to follow multi-step reasoning processes"
  - name: summary_quality
    enabled: true
    description: "Evaluates quality of text summarization"

# Task types and their configurations
tasks:
  - name: qa
    description: "Question Answering tasks"
    metrics:
      - hallucination
      - answer_relevance
      - conciseness
      - fluency
      - reasoning_quality
      - factual_accuracy
      - technical_nuance
      - multistep_reasoning
      - empathy

  - name: summarization
    description: "Text summarization tasks"
    metrics:
      - hallucination
      - summary_quality
      - conciseness
      - fluency
      - factual_accuracy
      - technical_nuance

  - name: chat
    description: "Conversational tasks"
    metrics:
      - fluency
      - toxicity
      - response_time
      - hallucination
      - empathy
      - technical_nuance
